{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_mutation</th>\n",
       "      <th>id_parcelle</th>\n",
       "      <th>adresse_numero</th>\n",
       "      <th>adresse_suffixe</th>\n",
       "      <th>adresse_nom_voie</th>\n",
       "      <th>adresse_code_voie</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>code_commune</th>\n",
       "      <th>nom_commune</th>\n",
       "      <th>code_departement</th>\n",
       "      <th>code_section</th>\n",
       "      <th>date_mutation</th>\n",
       "      <th>surface_reelle_bati</th>\n",
       "      <th>surface_terrain</th>\n",
       "      <th>valeur_fonciere</th>\n",
       "      <th>prix_m2</th>\n",
       "      <th>considered_for_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_mutation, id_parcelle, adresse_numero, adresse_suffixe, adresse_nom_voie, adresse_code_voie, code_postal, code_commune, nom_commune, code_departement, code_section, date_mutation, surface_reelle_bati, surface_terrain, valeur_fonciere, prix_m2, considered_for_average]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import json\n",
    "import math\n",
    "from pandas.io.json import json_normalize  \n",
    "import datetime as dt\n",
    "\n",
    "TEST_MODE=True\n",
    "\n",
    "def getAsFloat(elem):\n",
    "    if (elem is not None) and (elem!='nan') and elem.replace('.','',1).isdigit():\n",
    "        return float(elem)\n",
    "    return 0\n",
    " \n",
    "def getAsInt(elem):\n",
    "    if (math.isnan(elem)):\n",
    "        return 0\n",
    "    return int(elem)\n",
    "\n",
    "def getAsDate(elem):\n",
    "    return pd.to_datetime(elem)\n",
    "\n",
    "def getAveragePrice(row):\n",
    "    if (row.surface_reelle_bati == 0):\n",
    "        return 0;\n",
    "    return int(row.valeur_fonciere/row.surface_reelle_bati);\n",
    "\n",
    "def getConsidered(row):\n",
    "    if (row.surface_reelle_bati == 0):\n",
    "        return 0;\n",
    "    if (row.surface_terrain > (2*row.surface_reelle_bati)):\n",
    "        return 0;\n",
    "    return 1;\n",
    "\n",
    "def getParcelleSection(parcelle):\n",
    "    return parcelle[5:10].strip('0')\n",
    "\n",
    "def getLastRelevantPrice(x, y):\n",
    "    if (x > 0):\n",
    "        return x\n",
    "    return y\n",
    "\n",
    "def is_outlier(s):\n",
    "    stdVal = s.std() * 3\n",
    "    meanVal = s.mean()\n",
    "    lower_limit = meanVal - stdVal\n",
    "    upper_limit = meanVal + stdVal\n",
    "    return ~s.between(lower_limit, upper_limit)\n",
    "\n",
    "\n",
    "def computeDataFrameMeanOnYear(s, group, year):\n",
    "    values = s[s['date_mutation'].dt.year == currentYear]\n",
    "    values = values.groupby(group)['prix_m2'].mean().reset_index();\n",
    "    return values.astype({group:'str'}).set_index(group)\n",
    "    \n",
    "\n",
    "def meanPriceDepartement(s, currentYear) :\n",
    "    values = s[~s.groupby('code_departement')['prix_m2'].apply(is_outlier)]\n",
    "    valuesLatest = computeDataFrameMeanOnYear(values, 'code_departement', currentYear)\n",
    "    valuesOld = computeDataFrameMeanOnYear(values, 'code_departement', currentYear-1)\n",
    "    latestKey = 'prix_m2_' + str(currentYear)\n",
    "    oldKey = 'prix_m2_' + str(currentYear-1)\n",
    "\n",
    "    values = pd.merge(valuesLatest, valuesOld, on='code_departement', \n",
    "                     suffixes=(\"_\" +str(currentYear-1), \"_\" +str(currentYear)))\n",
    "    values['prix_m2'] = values[[latestKey, oldKey]].apply(lambda row: row[latestKey] if row[latestKey] >0 else row[oldKey], axis=1)\n",
    "    values['evolution'] = values[[latestKey, oldKey]].apply(lambda row: (row[latestKey]/row[oldKey])-1.0 if (row[latestKey] >0) and (row[oldKey] >0.0) else 0, axis=1)\n",
    "    return values\n",
    "\n",
    "\n",
    "def meanPriceCities(s) :\n",
    "    values = s[~s.groupby('code_commune')['prix_m2'].apply(is_outlier)]      \n",
    "    values = values.groupby('code_commune').aggregate({'code_departement': 'first',\n",
    "                                                       'prix_m2': 'mean'}).reset_index();        \n",
    "    return values.astype({'code_commune':'str'}).set_index('code_commune')\n",
    "\n",
    "\n",
    "def meanPriceSections(s) :\n",
    "    values = s[~s.groupby('code_section')['prix_m2'].apply(is_outlier)]\n",
    "    values = values.groupby(['code_commune', 'code_section']).aggregate({'prix_m2': 'mean'}).reset_index();       \n",
    "    return values.astype({'code_section':'str'}).set_index('code_section')\n",
    "\n",
    "\n",
    "\n",
    "def meanPriceParcelles(s) :\n",
    "    values = s.groupby(['code_commune', 'code_section', 'id_parcelle']).aggregate({'prix_m2': 'mean'}).reset_index();       \n",
    "    return values.astype({'id_parcelle':'str'}).set_index('id_parcelle')\n",
    "\n",
    "\n",
    "def getDepartementDetails() :\n",
    "    with open(\"C:\\\\Users\\\\pifoyard\\\\Desktop\\\\NoCode\\\\MyCSV\\\\departements-100m.geojson\", encoding='utf-8') as data_file:    \n",
    "        data = json.load(data_file)  \n",
    "    geo = json_normalize(data['features']) \n",
    "    geo.rename(columns={'properties.code': 'code_departement', 'properties.nom': 'departement', 'properties.region': 'code_region'}, inplace=True)\n",
    "    geo.set_index('code_departement')    \n",
    "\n",
    "    # Load regions\n",
    "    with open(\"C:\\\\Users\\\\pifoyard\\\\Desktop\\\\NoCode\\\\MyCSV\\\\regions.json\", encoding='utf-8') as data_file:    \n",
    "        data = json.load(data_file)  \n",
    "    regions = json_normalize(data) \n",
    "    regions.rename(columns={'nom': 'region', 'code': 'code_region'}, inplace=True)\n",
    "    regions.set_index('code_region')\n",
    "\n",
    "    # Remove first 0\n",
    "    geo['code_region']=geo['code_region'].map(lambda x: x.lstrip('0'))\n",
    "    geo['code_departement']=geo['code_departement'].map(lambda x: x.lstrip('0'))\n",
    "    regions['code_region']=regions['code_region'].map(lambda x: x.lstrip('0'))\n",
    "\n",
    "    # Join regions and geo info\n",
    "    return geo.merge(regions, on='code_region', how='left').astype({'code_departement':'str'}).set_index('code_departement')\n",
    "\n",
    "\n",
    "def buildDepartementsFile(consideredValues, filePath, currentYear):\n",
    "    departements = meanPriceDepartement(consideredValues, currentYear)\n",
    "\n",
    "    # Enrich with departement geozon\n",
    "    if (TEST_MODE == False):\n",
    "        details = getDepartementDetails()\n",
    "        departements = details.join(departements)\n",
    "\n",
    "    # round and set price to default value if required\n",
    "    departements['prix_m2']=departements['prix_m2'].apply(getAsInt);\n",
    "    \n",
    "    # Save file\n",
    "    departements.to_csv(filePath)\n",
    "\n",
    "    \n",
    "def buildCitiesFile(consideredValues, filePath):\n",
    "    cities = meanPriceCities(consideredValues)\n",
    "\n",
    "    # round and set price to default value if required\n",
    "    cities['prix_m2']=cities['prix_m2'].apply(getAsInt);\n",
    "    \n",
    "    # Save file\n",
    "    cities.to_csv(filePath)\n",
    "\n",
    "def buildSectionsFile(consideredValues, filePath):\n",
    "    sections = meanPriceSections(consideredValues)\n",
    "\n",
    "    # round and set price to default value if required\n",
    "    sections['prix_m2']=sections['prix_m2'].apply(getAsInt);\n",
    "    \n",
    "    # Save file\n",
    "    sections.to_csv(filePath)    \n",
    "\n",
    "    \n",
    "\n",
    "def buildParcellesFile(consideredValues, filePath):\n",
    "    sections = meanPriceParcelles(consideredValues)\n",
    "\n",
    "    # round and set price to default value if required\n",
    "    sections['prix_m2']=sections['prix_m2'].apply(getAsInt);\n",
    "    \n",
    "    # Save file\n",
    "    sections.to_csv(filePath)    \n",
    "        \n",
    "\n",
    "# Load year values from: https://cadastre.data.gouv.fr/data/etalab-dvf/latest/csv/$YEAR/full.csv.gz\n",
    "# Read source file\n",
    "def extractFiles(files):   \n",
    "    dataFrames = []\n",
    "    for file in files:\n",
    "        dataFrames.append(pd.read_csv( file, \n",
    "                                       sep=',',\n",
    "                                       converters = {'lot1_surface_carrez': getAsFloat,\n",
    "                                                     'lot2_surface_carrez': getAsFloat,\n",
    "                                                     'lot3_surface_carrez': getAsFloat,\n",
    "                                                     'lot4_surface_carrez': getAsFloat,\n",
    "                                                     'lot5_surface_carrez': getAsFloat,\n",
    "                                                     'surface_reelle_bati': getAsFloat,\n",
    "                                                     'surface_terrain': getAsFloat,\n",
    "                                                     'valeur_fonciere': getAsFloat,\n",
    "                                                     'date_mutation': getAsDate\n",
    "                                                    },\n",
    "                                      encoding='utf-8'));\n",
    "    data = pd.concat(dataFrames);\n",
    "\n",
    "    # Build surface as max\n",
    "    data['lot1_surface_carrez']=data[['lot1_surface_carrez',\n",
    "                                    'lot2_surface_carrez',\n",
    "                                    'lot3_surface_carrez',\n",
    "                                    'lot4_surface_carrez',\n",
    "                                    'lot5_surface_carrez']].sum(axis=1);\n",
    "    data['surface_reelle_bati']=data[['lot1_surface_carrez','surface_reelle_bati']].max(axis=1);\n",
    "\n",
    "    # Prepare set of mutations\n",
    "    mutations = data.groupby('id_mutation').aggregate({ 'date_mutation': 'first',\n",
    "                                                        'surface_reelle_bati': 'sum',\n",
    "                                                        'surface_terrain': lambda x: x.unique().sum(),\n",
    "                                                        'valeur_fonciere': 'max'}).reset_index();\n",
    "    mutations['prix_m2']=mutations.apply(getAveragePrice, axis=1);\n",
    "    mutations['considered_for_average']=mutations.apply(getConsidered, axis=1);\n",
    "\n",
    "    # Prepare set of parcelles\n",
    "    parcelles = data.groupby(['id_mutation', 'id_parcelle']).aggregate({'adresse_numero': 'first',\n",
    "                                                                        'adresse_suffixe': 'first',\n",
    "                                                                        'adresse_nom_voie': 'first',\n",
    "                                                                        'adresse_code_voie': 'first',                                                        \n",
    "                                                                        'code_postal': 'first',\n",
    "                                                                        'code_commune': 'first',\n",
    "                                                                        'nom_commune': 'first',\n",
    "                                                                        'code_departement': 'first'}).reset_index();\n",
    "    parcelles['code_section'] = parcelles['id_parcelle'].apply(getParcelleSection)\n",
    "\n",
    "    # Complement parcelles with mutations\n",
    "    mergedParcellesAndMutations = parcelles.join(mutations.set_index('id_mutation'), on= 'id_mutation')\n",
    "\n",
    "    ######################################\n",
    "    # MEAN CALCULATION\n",
    "\n",
    "    # Remove rows not considered for average\n",
    "    consideredValues = mergedParcellesAndMutations[mergedParcellesAndMutations.considered_for_average != 0]\n",
    "    return consideredValues;\n",
    "    \n",
    "    \n",
    "##############################################\n",
    "##              MAIN                        ##\n",
    "## Compute average price ignoring outliers  ##\n",
    "##############################################\n",
    "folder = \"C:\\\\Users\\\\pifoyard\\\\Desktop\\\\NoCode\\\\MyCSV\\\\\"\n",
    "currentYear=2019\n",
    "consideredValues = extractFiles([folder + \"full2019\" + \".csv\"]);\n",
    "consideredValues[consideredValues['code_departement']==57].head()\n",
    "\n",
    "#buildDepartementsFile(consideredValues, folder + \"departements.csv\", currentYear)\n",
    "#buildCitiesFile(consideredValues, folder + \"cities.csv\")\n",
    "#buildSectionsFile(consideredValues, folder + \"sections.csv\")\n",
    "#buildParcellesFile(consideredValues, folder + \"parcelles.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
